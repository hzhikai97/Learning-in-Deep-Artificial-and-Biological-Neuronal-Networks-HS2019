\documentclass[main]{subfiles}


\begin{document}
\newpage
\section{Deep Learning With Spikes}


\subsection{Motivation}
Neurobiology mostly uses spiking neural networks. Neurons output spikes, which are binary events and localized in time. 

So how do hidden units learn?
\paragraph{Bottom-up approach:}
\begin{itemize}
    \item Start with a random network model
    \item Include data driven plasticity model
    \item Observe function $\rightarrow$ Limited success in learning useful hidden layer representations
\end{itemize}
One outcome would be Spike-time dependent plasticity (STDP), which is a way the weights can be adjusted. So far not very useful in building networks; the weights tend to blow up. Over the years, people went over this concept and tried to improve. 

\paragraph{Top-down approach:}
\begin{itemize}
    \item Start with function in mind
    \item Derive suitable plasticity rules
    \item Build functional network models
\end{itemize}
Deep learning is an example of a top-down framework. Two questions remain: 

\textbf{The algorithmic question:} How to compute the gradient?

\textbf{The conceptual question:} Which functions are learned?

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{10_DeepLearningWithSpikes/figures/deeplearning.png}
    \caption{Deep learning as a top-down framework}
    \label{fig:my_label}
\end{figure}

\subsection{Recap: Spiking Neuron Models}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{10_DeepLearningWithSpikes/figures/snn.png}
    \caption{Illustration of a Spiking Neural Network}
    \label{fig:my_label}
\end{figure}

\begin{itemize}
    \item Spiking networks consist of spiking neurons
    \item Network modeling largely relies on simplified neuron models
\end{itemize}

\subsubsection{Biophysics of neuronal signal transmission}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.99\linewidth]{10_DeepLearningWithSpikes/figures/biophysics.png}
    \caption{}
    \label{fig:my_label}
\end{figure}

\subsubsection{From biophysical to reduced neuron models}
In order to build a phenomenological model of neuronal dynamics\footnote{Incredibly useful and free book by Wulfram Gernster et. al, where most of the content of this section is copy-pasted from: \url{https://neuronaldynamics.epfl.ch/online/index.html}}, we describe the critical voltage for spike initiation by a formal threshold $\theta$. If the voltage $U_i(t)$ (that contains the summed effect of all inputs) reaches $\theta$ from below, we say that neuron $i$ fires a \textbf{spike}. The moment of threshold crossing defines the firing time $t^{(f)}_i$. 
The model makes use of the fact that neuronal action potentials of a given neuron always have roughly the same form. If the shape of an action potential is always the same, then the shape cannot be used to transmit information: rather information is contained in the presence or absence of a spike. Therefore action potentials are reduced to ‘events’ that happen at a precise moment in time.



\paragraph{Leaky integrate-and-fire neuron: }
Neuron models where action potentials are described as events are called 'Integrate-and-Fire' models. No attempt is made to describe the shape of an action potential. Integrate-and-fire models have two separate components that are both necessary to define their dynamics:
\begin{enumerate}
    \item An equation that describes the evolution of the membrane potential $U_i(t)$
    \item A mechanism to generate spikes.
\end{enumerate}
The variable $U_i$ describes the momentary value of the membrane potential of neuron $i$. In the absence of any input, the potential is at its resting value $U_{rest}$. If an experimentalist injects a current $I(t)$ into the neuron, or if the neuron receives synaptic input from other neurons, the potential $U_i(t)$ will be deflected from its resting value. The basic electrical circuit representing a leaky integrate-and-fire model consists of a capacitor $C$ in parallel with a resistor $R$ driven by a current $I(t)$, as shown in the figure below. The differential equation for describing the leaky-integration of the voltage is given by
%
\begin{equation}
\tau \frac{\mathrm{d}}{\mathrm{d} t} U(t)=-\left(U(t)-U_{\mathrm{rest}}\right)+R_{\mathrm{in}} I(t),
\end{equation}
where $\tau = RC$ is the time constant of the circuit. 
%
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{10_DeepLearningWithSpikes/figures/passive_membrane.png}
    \caption{Passive Membrane}
    \label{fig:my_label}
\end{figure}
%
Now the second part of the leaky integrate-and-fire neuron is the firing and re-setting of the voltage after the neuron-specific threshold has been reached. At the firing time $t^{f}: U(t^{f}) = \theta$, the neuron fires (with a not-here-to-be-defined spike-form), the firing time is noted and immediately after the voltage reset to a new value $U_{rest} < \theta$:
\begin{equation}
    \lim_{\delta \to 0; \delta > 0} U(t^{(f)} + \delta) = U_{rest}
\end{equation}
%
\paragraph{}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{10_DeepLearningWithSpikes/figures/leaky_ifn.png}
    \caption{}
    \label{fig:my_label}
\end{figure}
%
\paragraph{Exponential postsynaptic currents: }
We also want to model the synapse. Activation of a presynaptic neuron results in a release of neurotransmitters into the synaptic cleft. The transmitter molecules diffuse to the other side of the cleft and activate receptors that are located in the postsynaptic membrane. In both cases, the activation of the receptor results in the opening of certain ion channels and, thus, in an excitatory or inhibitory postsynaptic transmembrane current (EPSC or IPSC). The main mechanism for carrier transport underlying this current is diffusion of the ions passing from the extracellular space into the cell. Instead of developing a mathematical model of the transmitter concentration in the synaptic cleft, we keep things simple and describe transmitter-activated ion channels as an explicitly time-dependent conductivity. This conductivity change most often modelled as an exponentially decaying function, to represent the effect of closing ion channels. The following differential equation describes the evolution of the postsynaptic current $I(t)$:
%
\begin{equation}\label{eq:syn}
\frac{\mathrm{d}}{\mathrm{d} t} I(t)=-\frac{I(t)}{\tau_{\mathrm{syn}}}+S(t)
\end{equation}
%

and is derived starting from the decaying exponential we want to model:

\begin{equation}
    I(t) = I_0 e^{\frac{-t}{\tau}}
\end{equation}
\begin{align}
    ln(I(t)) &= ln(I_0) + ln(e^{\frac{-t}{\tau}}) \\
    &= ln(I_0) - \frac{t}{\tau} | \frac{dI(t)}{dt} \\
    \frac{1}{I(t)} \frac{I(t)}{dt} &= -\frac{1}{\tau} \\
    \frac{dI(t)}{dt} &= -\frac{I(t)}{\tau} 
\end{align}

Considering the changes arising due to the discrete APs, the term $S(t)$ added in Equation \ref{eq:syn} determines an instantaneous increase in the postsynaptic current proportional to the synaptic weight.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{10_DeepLearningWithSpikes/figures/exp_ps_current.png}
    \caption{}
    \label{fig:my_label}
\end{figure}
%
\paragraph{The spike response model (SRM):}
\hl{?? Also here} 
So far, we have described neuronal dynamics in terms of systems of differential equations. There is another approach called the ‘filter picture’. In this picture, the parameters of the model are replaced by (parametric) functions of time, generically called ‘filters’. The neuron model is therefore interpreted in terms of a membrane filter as well as a function describing the shape of the spike and, potentially, also a function for the time course of the threshold. Together, these three functions establish the Spike Response Model (SRM). More info here: https://neuronaldynamics.epfl.ch/online/Ch6.S4.html

Mathematically speaking, we integrate over the differential equation, then replace the integration times multiplications with convolutions of filter kernels over the spikes:
%
\begin{equation}
\mathrm{U}_{i}(t)=\sum_{j} w_{i j}\left(\epsilon * S_{j}\right)(t)+\left(\eta * S_{i}\right)(t)+U_{\mathrm{rest}}
\end{equation}
%
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{10_DeepLearningWithSpikes/figures/spike_response_model.png}
    \caption{}
    \label{fig:my_label}
\end{figure}
%
\paragraph{Towards functional neural network models: }
We want this
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{10_DeepLearningWithSpikes/figures/towards_functional_nn.png}
    \caption{}
    \label{fig:my_label}
\end{figure}

\subsection{Dealing with the Vanishing Gradient Problem}

\subsubsection{Defining the problem}
Can we do supervised learning in spiking multi-layer networks with a local online learning rule? We want to compare output spikes with target spikes. Let's try:
\paragraph{Van Rossum distance between output and target spike trains:}
There is different ways of representing a spike train. If the spikes are seen to be discrete units, the spike train $S(t)$ is given simply by
%
\begin{equation}
    S(t) = \sum_i^M \delta(t-t_i)
\end{equation}
%
Replacing the delta function associated with each spike with an exponential function, that is, add an exponential tail to all spikes, leads to another definition of a spike train:
%
\begin{equation}
    S(t) = \sum_i^M H(t-t_i)\exp{-(t-t_i)/t_c},
\end{equation}
%
where $H(t)$ is the heavyside function. The loss between the target spikes distance $\hat{S}$ and the output spikes distance $S$ can be defined as the Van Rossum distance:
%
\begin{equation}
\mathcal{L}=\frac{1}{2} \int_{-\infty}^{t}[\lambda *(\hat{S}(s)-S(s))]^{2} ds
\end{equation}
%
The problem with our spike model and such a loss becomes evident when we try to differentiate the loss with respect to the single weights:
%
\begin{equation}
-\frac{\partial \mathcal{L}}{\partial w_{k}}=\int_{-\infty}^{t} \lambda *(\hat{S}(s)-S(s)) \lambda * \frac{\partial S(t)}{\partial w_{k}} d s
\end{equation}
%
The partial derivation $\frac{\partial S(t)}{\partial w_{k}}$ This derivative is problematic because for most neuron models, it is zero except at spike times at which it is not defined. Thus it forces the gradient to vanish. 
%
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{10_DeepLearningWithSpikes/figures/vanishing.png}
    \caption{}
    \label{fig:my_label}
\end{figure}
%

\subsubsection{A history of struggle}

\paragraph{Noise injection :}\footnote{Pfister, Toyoizumi, Barber \& Gerstner (2006), Gardner, Sporea & Grüning (2015)} \hl{Write smth here.}

\paragraph{Differentiate firing times :}\footnote{Bohte, Kok, & Poutre (2002), Gütig \& Sompolinski (2006), Gütig (2016), Mostafa (2018)} (skipped in lecture)

\paragraph{Make spikes differentiable :}\footnote{Huh \& Sejnowski (2018)}

\paragraph{Force hidden units "on target" :}\footnote{Gilra \& Gerstner (2017), Nicola & Clopath (2017)}

\paragraph{e.g. firing-rate approaches :}\footnote{Hunsberger \& Eliasmith (2015), Lee et al. (2016), ...}

\newpage
\subsubsection{Surrogate gradients \& SuperSpike}
Idea\footnote{Zenke \& Ganguli, "SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks", 2018}: Replace the non-differentiable heaviside function with the differentiable sigmoid function $\sigma$, but only in the backward-pass. In the forward pass, leave it as a heaviside function. The equivalent in machine learning would be "Straight-through estimators"\footnote{Begio et al., "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation", 2013}. This procedure leads to the replacements:
%
\begin{equation}
\frac{\partial S_{i}}{\partial w_{i j}} \quad \rightarrow \quad \sigma^{\prime}\left(U_{i}\right) \frac{\partial U_{i}}{\partial w_{i j}}
\end{equation}
%
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{10_DeepLearningWithSpikes/figures/surrogate_gradient.png}
    \caption{}
    \label{fig:my_label}
\end{figure}
%
If now the membrane potential $U_i(t)$ is written in the integral form as a spike response model ($SRM_0$)
%
\begin{equation}
\mathrm{U}_{i}(t)=\sum_{j} w_{i j}\left(\epsilon * S_{j}\right)(t)+\left(\eta * S_{i}\right)(t)+U_{\mathrm{rest}}, 
\end{equation}
%
where $\epsilon$ is the causal membrane kernel (corresponding to the postsynaptic potential) and $\eta$ captures spike dynamics and reset. With some steps that are briefly explained in the paper, one gets for the gradient descent learning rule for a single neuron the following expression:
%
\begin{equation}
\frac{\partial w_{i j}}{\partial t}=r \int_{-\infty}^{t}  \lambda *( \underbrace{\left(\epsilon * S_{j}\right)(s)}_{\text {Pre }} \underbrace{\sigma^{\prime}\left(U_{i}(s)\right)}_{\text {Post }}) \underbrace{e_{i}(s)}_{\text {Error signal }} ds
\end{equation}
%
Here, $r$ is the learning rate, $e_{i}(s)=\lambda*(\hat{S_i}-S_i)$ the error signal and $\lambda$ the eligibility trace ("Ca transient"). This learning rule is called \textbf{SuperSpike}. We can divide this rule into three factors:
%
\begin{itemize}
    \item[\textbf{Pre}] Presynaptic activity
    \item[\textbf{Post}] Postsynaptic activity
    \item[\textbf{Error signal}] Specific feedback
\end{itemize}
%
The pre- and postsynaptic activity are combined in a multiplicative manner, which can be seen as the Hebbian term (which is "STDP"-like). $\sigma^'$ is the voltage nonlinearity, thus the learning rule is voltage based. 

\subsubsection{Hidden layers}
What about training the hidden layers? The learning rule for hidden weights is 
%
\begin{equation}
\frac{\partial w_{i j}}{\partial t} \equiv \sum_{k} e_{k}(t) \epsilon *\left[w_{k i} \epsilon *\left(\epsilon * S_{j}(t) \sigma^{\prime}\left(U_{i}\right)\right) \sigma^{\prime}\left(U_{k}\right)\right].
\end{equation}
%
Biologically seen this is problematic, because
\begin{enumerate}
    \item It requires symmetric weights
    \item There are downstream activities
\end{enumerate}
One way to overcome those issues is by applying feedback-alignment, which is well documented in \cref{sec:training}. Note that all quantities computed online. Temporal credit assignment through dynamics at the synaptic level (eligibility trace).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{10_DeepLearningWithSpikes/figures/feedbackalignment.png}
    \caption{Network trained to solve a non-linearly separable classification problem with noisy input neurons. \textbf{(a)} Sketch of network layout with two output units and four hidden units. \textbf{(b)} Snapshot of network activity at the end of training with random feedback. Four input patterns from two non-linearly separable classes are presented in random order (shaded areas). In between stimulus periods, input neurons spike randomly with 4 Hz background firing rate. \textbf{(c)} Learning curves of 20 trials with different random initialisations (gray) for a network with random feedback connections that solves the task. The average of all trials is given by the black line. The average of 20 simulation trials with an additional regularization term (see section 3) is shown in green. \textbf{(d)} Same as panel c but for a network without hidden units that cannot solve the task. \textbf{(e)} Same as panel c but for symmetric feedback. \textbf{(f)} Same as panel c but for uniform ("all ones") feedback connections.}
    \label{fig:my_label}
\end{figure}


\subsubsection{Sequence-to-sequence learning}
Because zero error was achieved with simple tasks using different types of feedback signal, the learning rule can be put to work in harsher conditions, under more challenging tasks: making it associate an spatio-temporal target output pattern to a repeating frozen Poisson noise input. In this case, a larger, 3-layer net was used (100 in, variable number hidden, 100 out), but an output pattern matching the target was achieved with only 32 hidden neurons. The random feedback performs worse than a network that was trained without a hidden layer, but with symmetrical weights.

%
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{10_DeepLearningWithSpikes/figures/spatio.PNG}
    \caption{Network trained to solve a nonlinearly separable classification problem with noisy input neurons. (a) Sketch of network layout with two output units and four hidden units. (b) Snapshot of network activity at the end of training with random feedback. Four input patterns from two nonlinearly separable classes are presented in random order (shaded areas). In between stimulus periods, input neurons spike randomly with 4 Hz background firing rate. (c) Learning curves of 20 trials with different random initializations (gray) for a network with random feedback connections that solves the task. The average of all trials is given by the black line. The average of 20 simulation trials with an additional regularization term (see section 3) is shown in green. (d) Same as panel c but fora network without hidden units that cannot solve the task. (e) Same as panel c but for symmetric feedback. (f) Same as panel c but for uniform (“all ones”) feedback connections.}
    \label{fig:my_label}
\end{figure}
%

The rule can also be used as an auto-encoder network, since it can be provided the same pattern as both input and output. It is able to reconstruct the output pattern with high fidelity while having a number of hidden units smaller than the number of units in the input and output layers.
\subsection{Spiking nets and temporal coding}

The RNN term is used in its widest sense, that of networks with states evolving in time based on well-defined dynamic recurrent equations. An important fact to note is that, while recurrent synaptic connections between neurons in a network give rise to recurrent dynamics, they are not absolutely necessary, as dynamical recurrent can arise without them. This is the case of neurons or synapses which have states which evolve according to internal dynamics: the current state depends on the previous state and the next state depends on the current state, thus state-full units are inherently recurrent.

This idea can be very well applied to SNNs, with computations necessary to update a cell state that can be unrolled in time as seen in Figure \ref{fig:snn_unroll}.

%
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{10_DeepLearningWithSpikes/figures/snns_unroll.PNG}
    \caption{Illustration of the computational graph of a SNN in discrete time. Time steps flow from left to right. Input spikes S(0) are fed into the network from the bottom and propagate upwards to higher layers. The synaptic currents I are decayed by $\alpha$ in each time step and fed into the membrane potentials U. The U are similarly decaying over time as characterized by $\beta$. Spike trains S are generated by applying a threshold non-linearity to the membrane potentials U in each time step. Spikes causally affect the network state (orange connections). First, each spike causes the membrane potential of the neuron that emits the spike to be reset. Second, each spike may be communicated to the same neuronal population via recurrent connections V(1). Finally, it may also be communicated via W(2) to another downstream network layer or, alternatively, a readout layer on which a cost function is defined.}
    \label{fig:snn_unroll}
\end{figure}
%

The Back-propagation rule can be applied to RNNs. In this case the recurrence is “unrolled” meaning that an auxiliary network is created by making copies of the network for each time step. The unrolled network is simply a deep network with shared feed-forward weights W(l) and recurrent weights V(l), on which the standard BP applies:

\begin{equation}
    \Delta W_{ij}^{(l)} \propto \frac{\partial \mathcal{L}[x]}{\partial W_{ij}^{(l)}} = \sum_{m=0}^t\delta_i^{(l)}[m]y_j^{(l-1)}[m]
\end{equation}

\begin{equation}
    \Delta V_{ij}^{(l)} \propto \frac{\partial \mathcal{L}[x]}{\partial V_{ij}^{(l)}} = \sum_{m=1}^t\delta_i^{(l)}[m-1]y_j^{(l)}[m-1]
\end{equation}

\begin{equation}
    \delta_{i}^{(l)}[n] = \sigma'\left(a_i^{(l)}[n]\right)\left(\sum_{k}\delta_k^{(l+1)}[n]W_{ij}^{(T,l)}+ (\sum_{k}\delta_k^{(l)}[n+1]V_{ij}^{(T,l)}\right)
\end{equation}

Applying BP to an unrolled network is referred to as back-propagation through time (BPTT).
\end{document}