\documentclass[main]{subfiles}


\begin{document}
\newpage
\section{Unsupervised And Self-Supervised Learning}

\subsection{Motivation}

Goeffrey Hinton (backprop\footnote{Learning representations by back-propagating errors}) suggests networks should be able to become intelligent on their own, unsupervised, without backprop.

Key features of unsupervised learning: 

\subsection{Unsupervised Learning in the Brain}

Kitten Experiments (vertical stripes)
Orientation and direction selective neurons in VI.
Mouse experiment (SCA)

Predict Neural Responses with DNN
Graph Clustering

\subsection{Unsupervised Machine Learning}

\subsubsection{Non-probabilistic UL Methods}
Sparse Coding
Math should be known!

Infomax (ICA) Clustering Method
Math
Neural Net


Autoencoders
Denoising AE
Sparse, Regularized AE
Contracting Autoencoder

Competitive Learning

Unsupervised Clustering Methods
KNN, K-Means

\subsubsection{Probabilistic (Generative} UL Methods
Separates in
Tractable Models:
Fully Observed Belief Nets
Pixel RNNs


Non-Tractable Models
Boltzmann Machine
Variational Autoencoders
Helmholtz Machines
(others)?

Other generative Models:
Generative Advarsarial Networks (GANs)
Moment-to-Moment Networks (not covered)

\subsubsection{Self-Supervised Learning}


\end{document}